instructions = """
You are a meticulous code reviewer. Evaluate the student's submission for the assignment:

LLM Agent POC — Browser-Based Multi-Tool Reasoning
Goal: A minimal browser JS agent that:
(1) takes user input,
(2) queries an LLM,
(3) dynamically triggers tool calls (search / AI Pipe / JS code exec) via OpenAI-style tool/function calls,
(4) loops until completion integrating tool results,
(5) provides a small, hackable UI with model picker and graceful error alerts.

Supported tools (must be implemented and callable by the agent):
- Google Search API: returns snippet results for user queries.
- AI Pipe proxy API (https://github.com/sanand0/aipipe).
- JavaScript code execution: securely run & display results inside the browser (sandboxed).

UI/Code Requirements:
- Model picker via bootstrap-llm-provider.
- OpenAI-style tool/function-calling interface for all tool invocations.
- Errors shown via bootstrap-alert.
- Keep JS/HTML small and simple (maximal hackability).
- May take inspiration from apiagent repo, but keep essentials only.

Grading (total 2.0 marks):
- Output functionality: 1.0
- Code quality & clarity: 0.5
- UI/UX polish & extras: 0.5

---------------------------
INPUT (student submission)
---------------------------
{{STUDENT_CODE}}
---------------------------

YOUR TASK
1) Do static analysis only. Do NOT assume behavior that is not explicitly present in code. If the requirement is not clearly implemented, mark it as “not found”.
2) Check for concrete signals (imports, function names, HTML elements, JSON shapes, fetch targets, tool schemas, sandbox usage, etc.). Quote tiny code excerpts (<=120 chars each) as evidence when relevant.
3) Score each sub-criterion with the specified weights; sum to category totals and then to overall. Never exceed max marks. Use 0 if absent. Use partial credit if partially satisfied.
4) Prefer precision over optimism. Simplicity and minimal code are rewarded when they still meet requirements.

DETECTION HEURISTICS (examples; use judgment)
- Agent loop & integration: look for a message array/log, repeated LLM calls, conditional execution of tool calls until no more, then user input appended; streaming print/update.
- OpenAI tool/function calling: presence of messages array, tools schema, tool_calls with {type:"function", function:{name, arguments}} or equivalent; handling of tool results back to the model.
- Google Search API: function or module clearly calling a search endpoint; look for “customsearch” or a named “search” tool returning snippets.
- AI Pipe proxy: code referencing “aipipe” or calling an endpoint documented for the aipipe proxy.
- JS code execution (sandboxed): usage of <iframe sandbox>, Web Worker, or other isolation. Using eval/Function in the main window without isolation is NOT sandboxed (flag).
- Model picker: usage of bootstrap-llm-provider via import/script tag or component invocation.
- Error UI: bootstrap-alert usage or a custom alert component built atop bootstrap-alert; graceful error display path.
- Minimality: small number of files, short code paths, limited deps; no large frameworks unless necessary.
- Security hygiene: sandbox for code exec; input sanitation for tool arguments; no exposed secrets; CORS/Origin considerations.

SCORING RUBRIC (assign exactly these weights)

A) Output functionality (max 1.0)
A1 Agent loop present, integrates tool outputs, continues until no more tool calls (0.20)
A2 OpenAI-style tool/function calling correctly wired (0.20)
A3 Google Search snippets tool implemented & integrated into loop (0.15)
A4 AI Pipe proxy tool implemented & integrated (0.15)
A5 JS code execution tool implemented & sandboxed (0.20)
A6 Streams/prints model output incrementally or clearly updates conversation window (0.10)

B) Code quality & clarity (max 0.5)
B1 Simplicity/minimal deps; small, hackable codebase (0.15)
B2 Readability (names, small functions, comments where needed) (0.10)
B3 Separation of concerns (UI vs agent vs tools) (0.10)
B4 Robust error handling paths (try/catch, user-visible messages) (0.10)
B5 Security hygiene beyond sandbox (no secrets in code, safe fetch, basic input validation) (0.05)

C) UI/UX polish & extras (max 0.5)
C1 Model picker via bootstrap-llm-provider (0.15)
C2 Error UI via bootstrap-alert (0.10)
C3 Clear conversation window & simple controls (send, run tool, etc.) (0.10)
C4 Small, discoverable UI affordances (copy to clipboard, status badges, keyboard submit, loading indicator) (0.10)
C5 Any tasteful extra that improves hackability without bloat (0.05)

SCORING RULES
- Use only the visible code. If uncertain, mark as “not found”.
- Partial credit: 0.5 of a sub-criterion if there is an incomplete or flawed implementation; 0.25 for a stub that is wired but obviously insufficient.
- “Sandboxed” means isolated via iframe sandbox, Worker, or equivalent. Plain eval in window scope ≠ sandboxed.
- Round category scores to 2 decimals; overall to 2 decimals.

OUTPUT FORMAT — STRICT JSON ONLY
Produce ONLY a JSON object matching this schema:

{
  "agent_loop": {"score": number, "max": 0.20, "reason": string },
  "openai_tool_calls": {"score": number, "max": 0.20, "reason": string },
  "google_search_tool": {"score": number, "max": 0.15, "reason": string },
  "aipipe_tool": {"score": number, "max": 0.15, "reason": string },
  "js_exec_sandboxed": {"score": number, "max": 0.20, "reason": string },
  "streaming_or_updates": {"score": number, "max": 0.10, "reason": string }
  "simplicity": {"score": number, "max": 0.15, "reason": string },
  "readability": {"score": number, "max": 0.10, "reason": string },
  "separation_of_concerns": {"score": number, "max": 0.10, "reason": string },
  "error_handling": {"score": number, "max": 0.10, "reason": string },
  "security_hygiene": {"score": number, "max": 0.05, "reason": string }
  "model_picker_bootstrap_llm_provider": {"score": number, "max": 0.15, "reason": string },
  "bootstrap_alert_errors": {"score": number, "max": 0.10, "reason": string },
  "conversation_ui_clarity": {"score": number, "max": 0.10, "reason": string },
  "useful_affordances": {"score": number, "max": 0.10, "reason": string },
  "extras_without_bloat": {"score": number, "max": 0.05, "reason": string }
}

VERDICT RULE OF THUMB
- pass: overall_score >= 1.6 and no critical missing tool (search, aipipe, sandboxed exec) and loop present
- borderline: 1.2–1.59 or 1 critical missing but strong other parts
- revise: < 1.2 or multiple critical misses

Remember: Output ONLY valid JSON. No commentary.
"""

[checks.agent_loop]
max = 0.20
check = """
Agent loop & integration: look for a message array/log, repeated LLM calls, conditional execution of tool calls until no more, then user input appended; streaming print/update.
"""

[checks.openai_tool_calls]
max = 0.20
check = """
OpenAI tool/function calling: presence of messages array, tools schema, tool_calls with {type:"function", function:{name, arguments}} or equivalent; handling of tool results back to the model.
"""

[checks.google_search_tool]
max = 0.15
check = """
Google Search API: function or module clearly calling a search endpoint; look for "customsearch" or a named "search" tool returning snippets.
"""

[checks.aipipe_tool]
max = 0.15
check = """
AI Pipe proxy: code referencing "aipipe" or calling an endpoint documented for the aipipe proxy.
"""

[checks.js_exec_sandboxed]
max = 0.20
check = """
JS code execution (sandboxed): usage of <iframe sandbox>, Web Worker, or other isolation. Using eval/Function in the main window without isolation is NOT sandboxed.
"""

[checks.streaming_or_updates]
max = 0.10
check = """
Streams/prints model output incrementally or clearly updates conversation window.
"""

[checks.simplicity]
max = 0.15
check = """
Simplicity/minimal deps; small, hackable codebase.
"""

[checks.readability]
max = 0.10
check = """
Readability (names, small functions, comments where needed).
"""

[checks.separation_of_concerns]
max = 0.10
check = """
Separation of concerns (UI vs agent vs tools).
"""

[checks.error_handling]
max = 0.10
check = """
Robust error handling paths (try/catch, user-visible messages).
"""

[checks.security_hygiene]
max = 0.05
check = """
Security hygiene: sandbox for code exec; input sanitation for tool arguments; no exposed secrets; CORS/Origin considerations.
"""

[checks.model_picker_bootstrap_llm_provider]
max = 0.15
check = """
Model picker via bootstrap-llm-provider.
"""

[checks.bootstrap_alert_errors]
max = 0.10
check = """
Error UI via bootstrap-alert.
"""

[checks.conversation_ui_clarity]
max = 0.10
check = """
Clear conversation window & simple controls (send, run tool, etc.).
"""

[checks.useful_affordances]
max = 0.10
check = """
Small, discoverable UI affordances (copy to clipboard, status badges, keyboard submit, loading indicator).
"""

[checks.extras_without_bloat]
max = 0.05
check = """
Any tasteful extra that improves hackability without bloat.
"""

